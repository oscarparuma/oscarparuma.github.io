{
 "metadata": {
  "name": "",
  "signature": "sha256:2e8918a4cd4d1668d87a328734550ca5a1a196e12a17c642b4683695892ba77a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ref: https://web2dot5.wordpress.com/2012/03/21/text-classification-in-python/\n",
      "# Ref: http://blog.yhathq.com/posts/naive-bayes-in-python.html\n",
      "\n",
      "import re\n",
      "import os\n",
      "import string\n",
      "\n",
      "def remove_punctuation(s):\n",
      "    \"see http://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\"\n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    return s.translate(table, string.punctuation)\n",
      " \n",
      "def tokenize(text):\n",
      "    text = remove_punctuation(text)\n",
      "    text = text.lower()\n",
      "    return re.split(\"\\W+\", text)\n",
      " \n",
      "def count_words(words):\n",
      "    wc = {}\n",
      "    for word in words:\n",
      "        wc[word] = wc.get(word, 0.0) + 1.0\n",
      "    return wc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train\n",
      "\n",
      "dataTrainDir = \"data/train/\"\n",
      "# setup some structures to store our data\n",
      "vocab = {}\n",
      "word_counts = {\n",
      "    \"spanish\": {},\n",
      "    \"english\": {},\n",
      "    \"french\": {}\n",
      "}\n",
      "priors = {\n",
      "    \"spanish\": 0.,\n",
      "    \"english\": 0.,\n",
      "    \"french\": 0.\n",
      "}\n",
      "docs = []\n",
      "for f in os.listdir(\"data/train\"):\n",
      "    f = f.strip()\n",
      "    if f.endswith(\".csv\") == False:\n",
      "        # skip non .csv files\n",
      "        continue\n",
      "    elif \"trainSet100Sp.csv\" in f:\n",
      "        category = \"spanish\"\n",
      "    elif \"trainSet100En.csv\" in f:\n",
      "        category = \"english\"\n",
      "    elif \"trainSet100Fr.csv\" in f:\n",
      "        category = \"french\"\n",
      "    docs.append((category, f))\n",
      "    priors[category] += 1\n",
      "    text = open(dataTrainDir + f).read()\n",
      "    words = tokenize(text)\n",
      "    counts = count_words(words)\n",
      "    for word, count in counts.items():\n",
      "        # if we haven't seen a word yet, let's add it to our dictionaries with a count of 0\n",
      "        if word not in vocab:\n",
      "            vocab[word] = 0.0\n",
      "        if word not in word_counts[category]:\n",
      "            word_counts[category][word] = 0.0\n",
      "        vocab[word] += count\n",
      "        word_counts[category][word] += count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test\n",
      "\n",
      "import math\n",
      "\n",
      "testDir = \"data/test/\"\n",
      "#testDoc = open(testDir + \"testSet100Sp.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100En.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100Fr.csv\").read()\n",
      "testDoc = open(testDir + \"testSet100De.csv\").read()\n",
      "words = tokenize(testDoc)\n",
      "counts = count_words(words)\n",
      "\n",
      "prior_spanish = (priors[\"spanish\"] / sum(priors.values()))\n",
      "prior_english = (priors[\"english\"] / sum(priors.values()))\n",
      "prior_french = (priors[\"french\"] / sum(priors.values()))\n",
      "\n",
      "log_prob_spanish = 0.0\n",
      "log_prob_english = 0.0\n",
      "log_prob_french = 0.0\n",
      "\n",
      "for w, cnt in counts.items():\n",
      "    # skip words that we haven't seen before, or words less than 3 letters long\n",
      "    if not w in vocab or len(w) <= 3:\n",
      "        continue\n",
      "    # calculate the probability that the word occurs at all\n",
      "    p_word = vocab[w] / sum(vocab.values())\n",
      "    # for all categories, calculate P(word|category), or the probability a \n",
      "    # word will appear, given that we know that the document is <category>\n",
      "    p_w_given_spanish = word_counts[\"spanish\"].get(w, 0.0) / sum(word_counts[\"spanish\"].values())\n",
      "    p_w_given_english = word_counts[\"english\"].get(w, 0.0) / sum(word_counts[\"english\"].values())\n",
      "    p_w_given_french = word_counts[\"french\"].get(w, 0.0) / sum(word_counts[\"french\"].values())\n",
      "    # add new probability to our running total: log_prob_<category>. if the probability \n",
      "    # is 0 (i.e. the word never appears for the category), then skip it\n",
      "    if p_w_given_spanish > 0:\n",
      "        log_prob_spanish += math.log(cnt * p_w_given_spanish / p_word)\n",
      "    if p_w_given_english > 0:\n",
      "        log_prob_english += math.log(cnt * p_w_given_english / p_word)\n",
      "    if p_w_given_french > 0:\n",
      "        log_prob_french += math.log(cnt * p_w_given_french / p_word)\n",
      " \n",
      "# print out the results; we need to go from logspace back to \"regular\" space,\n",
      "# so we take the EXP of the log_prob\n",
      "print \"Score(spanish):\", math.exp(log_prob_spanish + math.log(prior_spanish))\n",
      "print \"Score(english):\", math.exp(log_prob_english + math.log(prior_english))\n",
      "print \"Score(french):\", math.exp(log_prob_french + math.log(prior_french))\n",
      "\n",
      "#testSet100Sp.csv\n",
      "#Score(spanish): 3.02240985965e+127\n",
      "#Score(english): 279342099.181\n",
      "#Score(french): 563.893354333\n",
      "\n",
      "#testSet100En.csv\n",
      "#Score(spanish): 5368498.18807\n",
      "#Score(english): 2.01867210401e+147\n",
      "#Score(french): 3025960.44281\n",
      "\n",
      "#testSet100Fr.csv\n",
      "#Score(spanish): 2737.14909534\n",
      "#Score(english): 208444199.512\n",
      "#Score(french): 2.62761729517e+101\n",
      "\n",
      "#testSet100De.csv\n",
      "#Score(spanish): 4.66277969722\n",
      "#Score(english): 6647696.78399\n",
      "#Score(french): 126402.30399"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score(spanish): 4.66277969722\n",
        "Score(english): 6647696.78399\n",
        "Score(french): 126402.30399\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Any-of\n",
      "\n",
      "# Spanish\n",
      "\n",
      "import re\n",
      "import os\n",
      "import string\n",
      "\n",
      "dataTrainDir = \"data/train/\"\n",
      "# setup some structures to store our data\n",
      "vocab = {}\n",
      "word_counts = {\n",
      "    \"spanish\": {},\n",
      "    \"nonspanish\": {}\n",
      "}\n",
      "priors = {\n",
      "    \"spanish\": 0.,\n",
      "    \"nonspanish\": 0.\n",
      "}\n",
      "docs = []\n",
      "for f in os.listdir(\"data/train\"):\n",
      "    f = f.strip()\n",
      "    if f.endswith(\".csv\") == False:\n",
      "        # skip non .csv files\n",
      "        continue\n",
      "    elif \"trainSet100Sp.csv\" in f:\n",
      "        category = \"spanish\"\n",
      "    elif \"trainSet100En.csv\" in f:\n",
      "        category = \"nonspanish\"\n",
      "    elif \"trainSet100Fr.csv\" in f:\n",
      "        category = \"nonspanish\"\n",
      "    docs.append((category, f))\n",
      "    priors[category] += 1\n",
      "    text = open(dataTrainDir + f).read()\n",
      "    words = tokenize(text)\n",
      "    counts = count_words(words)\n",
      "    for word, count in counts.items():\n",
      "        # if we haven't seen a word yet, let's add it to our dictionaries with a count of 0\n",
      "        if word not in vocab:\n",
      "            vocab[word] = 0.0\n",
      "        if word not in word_counts[category]:\n",
      "            word_counts[category][word] = 0.0\n",
      "        vocab[word] += count\n",
      "        word_counts[category][word] += count\n",
      "\n",
      "# Test\n",
      "\n",
      "import math\n",
      "\n",
      "testDir = \"data/test/\"\n",
      "#testDoc = open(testDir + \"testSet100Sp.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100En.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100Fr.csv\").read()\n",
      "testDoc = open(testDir + \"testSet100De.csv\").read()\n",
      "words = tokenize(testDoc)\n",
      "counts = count_words(words)\n",
      "\n",
      "prior_spanish = (priors[\"spanish\"] / sum(priors.values()))\n",
      "prior_nonspanish = (priors[\"nonspanish\"] / sum(priors.values()))\n",
      "\n",
      "log_prob_spanish = 0.0\n",
      "log_prob_nonspanish = 0.0\n",
      "\n",
      "for w, cnt in counts.items():\n",
      "    # skip words that we haven't seen before, or words less than 3 letters long\n",
      "    if not w in vocab or len(w) <= 3:\n",
      "        continue\n",
      "    # calculate the probability that the word occurs at all\n",
      "    p_word = vocab[w] / sum(vocab.values())\n",
      "    # for all categories, calculate P(word|category), or the probability a \n",
      "    # word will appear, given that we know that the document is <category>\n",
      "    p_w_given_spanish = word_counts[\"spanish\"].get(w, 0.0) / sum(word_counts[\"spanish\"].values())\n",
      "    p_w_given_nonspanish = word_counts[\"nonspanish\"].get(w, 0.0) / sum(word_counts[\"nonspanish\"].values())\n",
      "    # add new probability to our running total: log_prob_<category>. if the probability \n",
      "    # is 0 (i.e. the word never appears for the category), then skip it\n",
      "    if p_w_given_spanish > 0:\n",
      "        log_prob_spanish += math.log(cnt * p_w_given_spanish / p_word)\n",
      "    if p_w_given_nonspanish > 0:\n",
      "        log_prob_nonspanish += math.log(cnt * p_w_given_nonspanish / p_word)\n",
      " \n",
      "# print out the results; we need to go from logspace back to \"regular\" space,\n",
      "# so we take the EXP of the log_prob\n",
      "print \"Score(spanish):\", math.exp(log_prob_spanish + math.log(prior_spanish))\n",
      "print \"Score(nonspanish):\", math.exp(log_prob_nonspanish + math.log(prior_nonspanish))\n",
      "\n",
      "#testSet100Sp.csv\n",
      "#Score(spanish): 3.02240985965e+127 *****\n",
      "#Score(nonspanish): 21346.8911115\n",
      "\n",
      "#testSet100En.csv\n",
      "#Score(spanish): 5368498.18807\n",
      "#Score(nonspanish): 3.69915740887e+84 *****\n",
      "\n",
      "#testSet100Fr.csv\n",
      "#Score(spanish): 2737.14909534\n",
      "#Score(nonspanish): 2.1772360453e+60 *****\n",
      "\n",
      "#testSet100De.csv\n",
      "#Score(spanish): 4.66277969722\n",
      "#Score(nonspanish): 150759.068523 *****"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score(spanish): 4.66277969722\n",
        "Score(nonspanish): 150759.068523\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Any-of\n",
      "\n",
      "# English\n",
      "\n",
      "import re\n",
      "import os\n",
      "import string\n",
      "\n",
      "dataTrainDir = \"data/train/\"\n",
      "# setup some structures to store our data\n",
      "vocab = {}\n",
      "word_counts = {\n",
      "    \"english\": {},\n",
      "    \"nonenglish\": {}\n",
      "}\n",
      "priors = {\n",
      "    \"english\": 0.,\n",
      "    \"nonenglish\": 0.\n",
      "}\n",
      "docs = []\n",
      "for f in os.listdir(\"data/train\"):\n",
      "    f = f.strip()\n",
      "    if f.endswith(\".csv\") == False:\n",
      "        # skip non .csv files\n",
      "        continue\n",
      "    elif \"trainSet100Sp.csv\" in f:\n",
      "        category = \"nonenglish\"\n",
      "    elif \"trainSet100En.csv\" in f:\n",
      "        category = \"english\"\n",
      "    elif \"trainSet100Fr.csv\" in f:\n",
      "        category = \"nonenglish\"\n",
      "    docs.append((category, f))\n",
      "    priors[category] += 1\n",
      "    text = open(dataTrainDir + f).read()\n",
      "    words = tokenize(text)\n",
      "    counts = count_words(words)\n",
      "    for word, count in counts.items():\n",
      "        # if we haven't seen a word yet, let's add it to our dictionaries with a count of 0\n",
      "        if word not in vocab:\n",
      "            vocab[word] = 0.0\n",
      "        if word not in word_counts[category]:\n",
      "            word_counts[category][word] = 0.0\n",
      "        vocab[word] += count\n",
      "        word_counts[category][word] += count\n",
      "\n",
      "# Test\n",
      "\n",
      "import math\n",
      "\n",
      "testDir = \"data/test/\"\n",
      "#testDoc = open(testDir + \"testSet100Sp.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100En.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100Fr.csv\").read()\n",
      "testDoc = open(testDir + \"testSet100De.csv\").read()\n",
      "words = tokenize(testDoc)\n",
      "counts = count_words(words)\n",
      "\n",
      "prior_english = (priors[\"english\"] / sum(priors.values()))\n",
      "prior_nonenglish = (priors[\"nonenglish\"] / sum(priors.values()))\n",
      "\n",
      "log_prob_english = 0.0\n",
      "log_prob_nonenglish = 0.0\n",
      "\n",
      "for w, cnt in counts.items():\n",
      "    # skip words that we haven't seen before, or words less than 3 letters long\n",
      "    if not w in vocab or len(w) <= 3:\n",
      "        continue\n",
      "    # calculate the probability that the word occurs at all\n",
      "    p_word = vocab[w] / sum(vocab.values())\n",
      "    # for all categories, calculate P(word|category), or the probability a \n",
      "    # word will appear, given that we know that the document is <category>\n",
      "    p_w_given_english = word_counts[\"english\"].get(w, 0.0) / sum(word_counts[\"english\"].values())\n",
      "    p_w_given_nonenglish = word_counts[\"nonenglish\"].get(w, 0.0) / sum(word_counts[\"nonenglish\"].values())\n",
      "    # add new probability to our running total: log_prob_<category>. if the probability \n",
      "    # is 0 (i.e. the word never appears for the category), then skip it\n",
      "    if p_w_given_english > 0:\n",
      "        log_prob_english += math.log(cnt * p_w_given_english / p_word)\n",
      "    if p_w_given_nonenglish > 0:\n",
      "        log_prob_nonenglish += math.log(cnt * p_w_given_nonenglish / p_word)\n",
      " \n",
      "# print out the results; we need to go from logspace back to \"regular\" space,\n",
      "# so we take the EXP of the log_prob\n",
      "print \"Score(english):\", math.exp(log_prob_english + math.log(prior_english))\n",
      "print \"Score(nonenglish):\", math.exp(log_prob_nonenglish + math.log(prior_nonenglish))\n",
      "\n",
      "#testSet100Sp.csv\n",
      "#Score(english): 279342099.181\n",
      "#Score(nonenglish): 5.85760568568e+69 *****\n",
      "\n",
      "#testSet100En.csv\n",
      "#Score(english): 2.01867210401e+147 *****\n",
      "#Score(nonenglish): 971394.688083\n",
      "\n",
      "#testSet100Fr.csv\n",
      "#Score(english): 208444199.512\n",
      "#Score(nonenglish): 7.03242647119e+57 *****\n",
      "\n",
      "#testSet100De.csv\n",
      "#Score(english): 6647696.78399 *****\n",
      "#Score(nonenglish): 335.305742197"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score(english): 6647696.78399\n",
        "Score(nonenglish): 335.305742197\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Any-of\n",
      "\n",
      "# French\n",
      "\n",
      "import re\n",
      "import os\n",
      "import string\n",
      "\n",
      "dataTrainDir = \"data/train/\"\n",
      "# setup some structures to store our data\n",
      "vocab = {}\n",
      "word_counts = {\n",
      "    \"french\": {},\n",
      "    \"nonfrench\": {}\n",
      "}\n",
      "priors = {\n",
      "    \"french\": 0.,\n",
      "    \"nonfrench\": 0.\n",
      "}\n",
      "docs = []\n",
      "for f in os.listdir(\"data/train\"):\n",
      "    f = f.strip()\n",
      "    if f.endswith(\".csv\") == False:\n",
      "        # skip non .csv files\n",
      "        continue\n",
      "    elif \"trainSet100Sp.csv\" in f:\n",
      "        category = \"nonfrench\"\n",
      "    elif \"trainSet100En.csv\" in f:\n",
      "        category = \"nonfrench\"\n",
      "    elif \"trainSet100Fr.csv\" in f:\n",
      "        category = \"french\"\n",
      "    docs.append((category, f))\n",
      "    priors[category] += 1\n",
      "    text = open(dataTrainDir + f).read()\n",
      "    words = tokenize(text)\n",
      "    counts = count_words(words)\n",
      "    for word, count in counts.items():\n",
      "        # if we haven't seen a word yet, let's add it to our dictionaries with a count of 0\n",
      "        if word not in vocab:\n",
      "            vocab[word] = 0.0\n",
      "        if word not in word_counts[category]:\n",
      "            word_counts[category][word] = 0.0\n",
      "        vocab[word] += count\n",
      "        word_counts[category][word] += count\n",
      "\n",
      "# Test\n",
      "\n",
      "import math\n",
      "\n",
      "testDir = \"data/test/\"\n",
      "#testDoc = open(testDir + \"testSet100Sp.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100En.csv\").read()\n",
      "#testDoc = open(testDir + \"testSet100Fr.csv\").read()\n",
      "testDoc = open(testDir + \"testSet100De.csv\").read()\n",
      "words = tokenize(testDoc)\n",
      "counts = count_words(words)\n",
      "\n",
      "prior_french = (priors[\"french\"] / sum(priors.values()))\n",
      "prior_nonfrench = (priors[\"nonfrench\"] / sum(priors.values()))\n",
      "\n",
      "log_prob_french = 0.0\n",
      "log_prob_nonfrench = 0.0\n",
      "\n",
      "for w, cnt in counts.items():\n",
      "    # skip words that we haven't seen before, or words less than 3 letters long\n",
      "    if not w in vocab or len(w) <= 3:\n",
      "        continue\n",
      "    # calculate the probability that the word occurs at all\n",
      "    p_word = vocab[w] / sum(vocab.values())\n",
      "    # for all categories, calculate P(word|category), or the probability a \n",
      "    # word will appear, given that we know that the document is <category>\n",
      "    p_w_given_french = word_counts[\"french\"].get(w, 0.0) / sum(word_counts[\"french\"].values())\n",
      "    p_w_given_nonfrench = word_counts[\"nonfrench\"].get(w, 0.0) / sum(word_counts[\"nonfrench\"].values())\n",
      "    # add new probability to our running total: log_prob_<category>. if the probability \n",
      "    # is 0 (i.e. the word never appears for the category), then skip it\n",
      "    if p_w_given_french > 0:\n",
      "        log_prob_french += math.log(cnt * p_w_given_french / p_word)\n",
      "    if p_w_given_nonfrench > 0:\n",
      "        log_prob_nonfrench += math.log(cnt * p_w_given_nonfrench / p_word)\n",
      " \n",
      "# print out the results; we need to go from logspace back to \"regular\" space,\n",
      "# so we take the EXP of the log_prob\n",
      "print \"Score(french):\", math.exp(log_prob_french + math.log(prior_french))\n",
      "print \"Score(nonfrench):\", math.exp(log_prob_nonfrench + math.log(prior_nonfrench))\n",
      "\n",
      "#testSet100Sp.csv\n",
      "#Score(french): 563.893354333\n",
      "#Score(nonfrench): 2.88230939706e+72 *****\n",
      "\n",
      "#testSet100En.csv\n",
      "#Score(french): 3025960.44281\n",
      "#Score(nonfrench): 2.36698799195e+85 *****\n",
      "\n",
      "#testSet100Fr.csv\n",
      "#Score(french): 2.62761729517e+101 *****\n",
      "#Score(nonfrench): 29939.2573137\n",
      "\n",
      "#testSet100De.csv\n",
      "#Score(french): 126402.30399 *****\n",
      "#Score(nonfrench): 1358.78830053"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score(french): 126402.30399\n",
        "Score(nonfrench): 1358.78830053\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# One-of\n",
      "\n",
      "#--------------------------------------------------------------\n",
      "# testSet100Sp.csv\n",
      "\n",
      "# Spanish classifier\n",
      "#Score(spanish): 3.02240985965e+127 *****\n",
      "#Score(nonspanish): 21346.8911115\n",
      "\n",
      "# English classifier\n",
      "#Score(english): 279342099.181\n",
      "#Score(nonenglish): 5.85760568568e+69\n",
      "\n",
      "# French classifier\n",
      "#Score(french): 563.893354333\n",
      "#Score(nonfrench): 2.88230939706e+72\n",
      "#--------------------------------------------------------------\n",
      "#--------------------------------------------------------------\n",
      "# testSet100En.csv\n",
      "\n",
      "# Spanish classifier\n",
      "#Score(spanish): 5368498.18807\n",
      "#Score(nonspanish): 3.69915740887e+84\n",
      "\n",
      "# English classifier\n",
      "#Score(english): 2.01867210401e+147 *****\n",
      "#Score(nonenglish): 971394.688083\n",
      "\n",
      "# French classifier\n",
      "#Score(french): 3025960.44281\n",
      "#Score(nonfrench): 2.36698799195e+85\n",
      "#--------------------------------------------------------------\n",
      "#--------------------------------------------------------------\n",
      "#testSet100Fr.csv\n",
      "\n",
      "# Spanish classifier\n",
      "#Score(spanish): 2737.14909534\n",
      "#Score(nonspanish): 2.1772360453e+60\n",
      "\n",
      "# English classifier\n",
      "#Score(english): 208444199.512\n",
      "#Score(nonenglish): 7.03242647119e+57\n",
      "\n",
      "# French classifier\n",
      "#testSet100Fr.csv\n",
      "#Score(french): 2.62761729517e+101 *****\n",
      "#Score(nonfrench): 29939.2573137\n",
      "#--------------------------------------------------------------\n",
      "#--------------------------------------------------------------\n",
      "#testSet100De.csv\n",
      "\n",
      "# Spanish classifier\n",
      "#Score(spanish): 4.66277969722\n",
      "#Score(nonspanish): 150759.068523\n",
      "\n",
      "# English classifier\n",
      "#Score(english): 6647696.78399 *****\n",
      "#Score(nonenglish): 335.305742197\n",
      "\n",
      "# French classifier\n",
      "#Score(french): 126402.30399\n",
      "#Score(nonfrench): 1358.78830053"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}